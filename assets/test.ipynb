{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "344443636c3027c5042750c9c609acdda283a9c43681b128a8c1053e7ad2aa7d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0,1,1,0]).reshape(4,1)\n",
    "X = np.array([\n",
    "    [0,0,1,0,1],\n",
    "    [0,1,0,0,0],\n",
    "    [0,1,1,0,0],\n",
    "    [1,0,0,1,0]])\n",
    "theta = np.array([1.5,2,1,2,3]).reshape(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood_function(theta,X,y):\n",
    "    lr_result = np.dot(X,theta)\n",
    "    ONE = np.ones([len(y),1])\n",
    "    return (-np.vdot(y,lr_result)+np.vdot(np.ones([4,1]),np.log(1+np.power(np.e,lr_result))))/len(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_function(theta,X,y):\n",
    "    lr_result = np.dot(X,theta)\n",
    "    return (-np.dot(X.T,y)+np.dot(X.T,np.power(np.e,lr_result)/(1+np.power(np.e,lr_result))))/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.24267194],\n",
       "       [-0.0416572 ],\n",
       "       [ 0.23364698],\n",
       "       [ 0.24267194],\n",
       "       [ 0.24550345]])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "gradient_function(theta,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(X,y,alpha):\n",
    "    theta = np.array([1.5,2,1,2,3]).reshape(5,1)\n",
    "    gradient = gradient_function(theta,X,y)\n",
    "    while not all(abs(gradient) <= 1e-5):\n",
    "        theta = theta - alpha*gradient\n",
    "        gradient = gradient_function(theta,X,y)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import WordMapper\n",
    "from feature import Preprocessor\n",
    "\n",
    "word_mapper = WordMapper()\n",
    "word_mapper.load_dict('dict.txt')\n",
    "\n",
    "preprocessor_model1 = Preprocessor(1,word_mapper)\n",
    "preprocessor_model2 = Preprocessor(2,word_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_model1.process('smalldata/train_data.tsv','eric_smalloutput/model1_formatted_train_data.tsv')\n",
    "preprocessor_model2.process('smalldata/train_data.tsv','eric_smalloutput/model2_formatted_train_data.tsv')\n",
    "preprocessor_model1.process('smalldata/test_data.tsv','eric_smalloutput/model1_formatted_test_data.tsv')\n",
    "preprocessor_model2.process('smalldata/test_data.tsv','eric_smalloutput/model2_formatted_test_data.tsv')\n",
    "preprocessor_model1.process('smalldata/valid_data.tsv','eric_smalloutput/model1_formatted_validation_data.tsv')\n",
    "preprocessor_model2.process('smalldata/valid_data.tsv','eric_smalloutput/model2_formatted_validation_data.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = np.array(['0','1','1','0']).reshape(4,1)\n",
    "X = np.array([\n",
    "    '0:1\\t2:1',\n",
    "    '0:1\\t1:1\\t2:1\\t3:1\\t4:1',\n",
    "    '1:1\\t3:1\\t4:1',\n",
    "    '4:1'])\n",
    "theta = np.array([1.5,2,1,2,3,2]).reshape(6,1)\n",
    "gradient = np.zeros([6,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_likelihood_function(theta,X,y):\n",
    "    num_of_instances = len(y)\n",
    "    result = 0\n",
    "    for i in range(num_of_instances):\n",
    "        label = int(y[i])\n",
    "        x = X[i].split('\\t')\n",
    "        lm_result = get_lm_result(theta,x)\n",
    "        result += -label*lm_result + np.log(1+np.power(np.e,lm_result))\n",
    "    return result/num_of_instances\n",
    "\n",
    "\n",
    "def get_lm_result(theta,x):\n",
    "    result = 0\n",
    "    bias = theta[-1][0]\n",
    "    for feature in x:\n",
    "        idx = int(feature.split(':')[0])\n",
    "        value = int(feature.split(':')[1])\n",
    "\n",
    "        result += value*theta[idx][0]\n",
    "    result += bias\n",
    "    return result\n",
    "\n",
    "def update_gradient(theta,gradient,x,label):\n",
    "    lm = get_lm_result(theta,x)\n",
    "    for feature in x:\n",
    "        idx = int(feature.split(':')[0])\n",
    "        value = int(feature.split(':')[1])\n",
    "\n",
    "        gradient[idx] = value*(-label+np.power(np.e,lm)/(1+np.power(np.e,lm)))\n",
    "    gradient[-1] = -label+np.power(np.e,lm)/(1+np.power(np.e,lm))\n",
    "    return gradient\n",
    "\n",
    "def stochastic_gradient_descent(theta,gradient,X,y,num_epoch):\n",
    "    alpha = 0.1\n",
    "    count = 0\n",
    "    while count < num_epoch:\n",
    "        count += 1\n",
    "        for i in range(len(y)):\n",
    "            label = int(y[i])\n",
    "            x = X[i].split('\\t')\n",
    "            gradient = update_gradient(theta,gradient,x,label)\n",
    "            theta = theta - alpha * gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature.py model1\n",
    "python feature.py smalldata/train_data.tsv smalldata/valid_data.tsv smalldata/test_data.tsv dict.txt eric_smalloutput/model1_formatted_train.tsv eric_smalloutput/model1_formatted_valid.tsv eric_smalloutput/model1_formatted_test.tsv 1\n",
    "## feature.py model2\n",
    "python feature.py smalldata/train_data.tsv smalldata/valid_data.tsv smalldata/test_data.tsv dict.txt eric_smalloutput/model2_formatted_train.tsv eric_smalloutput/model2_formatted_valid.tsv eric_smalloutput/model2_formatted_test.tsv 2\n",
    "## lr.py model1\n",
    "python lr.py eric_smalloutput/model1_formatted_train.tsv eric_smalloutput/model1_formatted_valid.tsv eric_smalloutput/model1_formatted_test.tsv dict.txt eric_smalloutput/model1_train_out.labels eric_smalloutput/model1_test_out.labels eric_smalloutput/model1_metrics_out.txt 30\n",
    "## lr.py model2\n",
    "python lr.py eric_smalloutput/model2_formatted_train.tsv eric_smalloutput/model2_formatted_valid.tsv eric_smalloutput/model2_formatted_test.tsv dict.txt eric_smalloutput/model2_train_out.labels eric_smalloutput/model2_test_out.labels eric_smalloutput/model2_metrics_out.txt 30\n",
    "\n",
    "## feature.py model1\n",
    "python feature.py largedata/train_data.tsv largedata/valid_data.tsv largedata/test_data.tsv dict.txt eric_largeoutput/model1_formatted_train.tsv eric_largeoutput/model1_formatted_valid.tsv eric_largeoutput/model1_formatted_test.tsv 1\n",
    "## feature.py model2\n",
    "python feature.py largedata/train_data.tsv largedata/valid_data.tsv largedata/test_data.tsv dict.txt eric_largeoutput/model2_formatted_train.tsv eric_largeoutput/model2_formatted_valid.tsv eric_largeoutput/model2_formatted_test.tsv 2\n",
    "## lr.py model1\n",
    "python lr.py eric_largeoutput/model1_formatted_train.tsv eric_largeoutput/model1_formatted_valid.tsv eric_largeoutput/model1_formatted_test.tsv dict.txt eric_largeoutput/model1_train_out.labels eric_largeoutput/model1_test_out.labels eric_largeoutput/model1_metrics_out.txt 200\n",
    "## lr.py model2\n",
    "python lr.py eric_largeoutput/model2_formatted_train.tsv eric_largeoutput/model2_formatted_valid.tsv eric_largeoutput/model2_formatted_test.tsv dict.txt eric_largeoutput/model2_train_out.labels eric_largeoutput/model2_test_out.labels eric_largeoutput/model2_metrics_out.txt 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = {'s':1,'d':2,'f':3}\n",
    "cf = {'d':2,'f':3,'s':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "cg == cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}